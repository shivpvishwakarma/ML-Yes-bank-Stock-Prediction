{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivpvishwakarma/Machine-Learning-Project/blob/main/Yes_Bank_Stock_Prediction_ML_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "**Submitted By-** Shiv Prasad Vishwakarma"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Summary: Yes Bank Stock Closing Price Prediction**\n",
        "\n",
        "The Yes Bank Stock Closing Price Prediction project aims to leverage historical stock data to forecast the closing price of Yes Bank, a prominent Indian financial institution. The dataset spans from July 2005 to November 2020, capturing the monthly open, high, low, and closing prices. The project focuses on using machine learning techniques to predict the stock's closing price, offering valuable insights for investors and analysts.\n",
        "\n",
        "**Data Analysis & Exploration:**\n",
        "\n",
        "The project begins with an extensive analysis of the dataset, examining key statistics, trends, and patterns. This analysis involves visualizations to understand the behavior of the stock prices over time. It includes examining the distribution of the closing prices and identifying any outliers or anomalies in the data. Additionally, the project explores the correlation between different features to understand their impact on the closing price.\n",
        "\n",
        "**Feature Engineering:**\n",
        "\n",
        "Feature engineering is a crucial step in this project, where new features are created from the existing ones to enhance the predictive power of the model. This involves creating lag features, moving averages, and other indicators that capture the historical behavior of the stock prices. It also involves scaling the data using MinMaxScaler to ensure that all features are on a similar scale, which is essential for many machine learning algorithms.\n",
        "\n",
        "**Model Selection and Training:**\n",
        "\n",
        "After feature engineering, the project moves on to model selection and training. It compares the performance of different regression models, such as Linear Regression, Decision Tree Regressor, and Random Forest Regressor, to identify the most suitable one for predicting the closing price. The project uses evaluation metrics like Mean Squared Error (MSE) and R-squared to measure the performance of each model.\n",
        "\n",
        "**Hyperparameter Tuning and Model Optimization:**\n",
        "\n",
        "To further improve the performance of the selected model, the project employs hyperparameter tuning techniques like GridSearchCV and RandomizedSearchCV. These techniques help in finding the best set of hyperparameters for the model, leading to enhanced predictive accuracy. The project also explores other optimization techniques like Bayesian Optimization to fine-tune the model.\n",
        "\n",
        "**Outlier and Missing Value Handling:**\n",
        "\n",
        "The project addresses outliers and missing values in the dataset using appropriate techniques. It uses z-scores to detect and remove outliers, ensuring that the model is not influenced by extreme values. For missing values, the project uses imputation methods such as mean, median, or mode to fill in the gaps, ensuring that the dataset is complete and ready for training.\n",
        "\n",
        "**Model Evaluation and Validation:**\n",
        "\n",
        "Once the model is trained and optimized, the project evaluates its performance using various metrics like Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared. It also performs cross-validation to ensure that the model's performance is consistent across different subsets of the data. This step is crucial for ensuring that the model is robust and reliable.\n",
        "\n",
        "**Conclusion and Insights:**\n",
        "\n",
        "The Yes Bank Stock Closing Price Prediction project concludes with valuable insights for investors and analysts. It provides a reliable model for predicting the closing price of Yes Bank stock based on historical data, enabling stakeholders to make informed decisions. The project also highlights the importance of feature engineering, model selection, and optimization in building an accurate predictive model. Overall, it serves as a valuable tool for understanding and forecasting the behavior of Yes Bank stock prices.**Project Summary: Yes Bank Stock Closing Price Prediction**\n",
        "\n",
        "The Yes Bank Stock Closing Price Prediction project aims to leverage historical stock data to forecast the closing price of Yes Bank, a prominent Indian financial institution. The dataset spans from July 2005 to November 2020, capturing the monthly open, high, low, and closing prices. The project focuses on using machine learning techniques to predict the stock's closing price, offering valuable insights for investors and analysts.\n",
        "\n",
        "**Data Analysis & Exploration:**\n",
        "\n",
        "The project begins with an extensive analysis of the dataset, examining key statistics, trends, and patterns. This analysis involves visualizations to understand the behavior of the stock prices over time. It includes examining the distribution of the closing prices and identifying any outliers or anomalies in the data. Additionally, the project explores the correlation between different features to understand their impact on the closing price.\n",
        "\n",
        "**Feature Engineering:**\n",
        "\n",
        "Feature engineering is a crucial step in this project, where new features are created from the existing ones to enhance the predictive power of the model. This involves creating lag features, moving averages, and other indicators that capture the historical behavior of the stock prices. It also involves scaling the data using MinMaxScaler to ensure that all features are on a similar scale, which is essential for many machine learning algorithms.\n",
        "\n",
        "**Model Selection and Training:**\n",
        "\n",
        "After feature engineering, the project moves on to model selection and training. It compares the performance of different regression models, such as Linear Regression, Decision Tree Regressor, and Random Forest Regressor, to identify the most suitable one for predicting the closing price. The project uses evaluation metrics like Mean Squared Error (MSE) and R-squared to measure the performance of each model.\n",
        "\n",
        "**Hyperparameter Tuning and Model Optimization:**\n",
        "\n",
        "To further improve the performance of the selected model, the project employs hyperparameter tuning techniques like GridSearchCV and RandomizedSearchCV. These techniques help in finding the best set of hyperparameters for the model, leading to enhanced predictive accuracy. The project also explores other optimization techniques like Bayesian Optimization to fine-tune the model.\n",
        "\n",
        "**Outlier and Missing Value Handling:**\n",
        "\n",
        "The project addresses outliers and missing values in the dataset using appropriate techniques. It uses z-scores to detect and remove outliers, ensuring that the model is not influenced by extreme values. For missing values, the project uses imputation methods such as mean, median, or mode to fill in the gaps, ensuring that the dataset is complete and ready for training.\n",
        "\n",
        "**Model Evaluation and Validation:**\n",
        "\n",
        "Once the model is trained and optimized, the project evaluates its performance using various metrics like Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared. It also performs cross-validation to ensure that the model's performance is consistent across different subsets of the data. This step is crucial for ensuring that the model is robust and reliable.\n",
        "\n",
        "**Conclusion and Insights:**\n",
        "\n",
        "The Yes Bank Stock Closing Price Prediction project concludes with valuable insights for investors and analysts. It provides a reliable model for predicting the closing price of Yes Bank stock based on historical data, enabling stakeholders to make informed decisions. The project also highlights the importance of feature engineering, model selection, and optimization in building an accurate predictive model. Overall, it serves as a valuable tool for understanding and forecasting the behavior of Yes Bank stock prices."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/shivpvishwakarma"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Visualize the monthly closing prices over the years to identify any general trends.\n",
        "2. Compare the highest and lowest monthly prices over the years to identify price volatility.\n",
        "3. Analyze the monthly price differences to understand the magnitude of fluctuations.\n",
        "4. Plot the monthly closing prices against the opening prices to observe potential patterns or discrepancies.\n",
        "5. Assess the correlation between monthly closing prices and the opening prices.\n",
        "6. Investigate the correlation between monthly closing prices and the highest and lowest prices.\n",
        "7. Predict the relationship between opening and closing prices using scatter plot and regression line.\n",
        "8. Predict monthly opening stock prices using seaborn's barplot for visualization and date-based subsetting.\n",
        "9. Investigate correlations between variables in \"yesdata\" using a heatmap for visualization and analysis.\n",
        "10. Visualize pairwise relationships between variables in a dataset using a pair plot for analysis."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from datetime import datetime as dt\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, confusion_matrix\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "url = \"/content/data_YesBank_StockPrices.csv\"\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "UVWUIWeca9gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df.isnull(), cbar = False)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **General Information:**\n",
        "   - The dataset has 185 entries (rows) with 5 columns.\n",
        "   - The columns include 'Date' (object), 'Open' (float64), 'High' (float64), 'Low' (float64), and 'Close' (float64).\n",
        "\n",
        "2. **Data Types:**\n",
        "   - The 'Date' column is of type 'object', suggesting that it may contain date information. However, for further analysis, it would be beneficial to convert it to a datetime type.\n",
        "\n",
        "3. **No Missing Values:**\n",
        "   - There are no missing values (null values) in any of the columns. Each column has 185 non-null entries.\n",
        "\n",
        "4. **Numerical Data:**\n",
        "   - The columns 'Open', 'High', 'Low', and 'Close' are of type float64, indicating that they likely represent numerical data.\n",
        "\n",
        "5. **Data Range:**\n",
        "   - The 'Open', 'High', 'Low', and 'Close' columns represent financial data, possibly related to stock prices, as they are common in financial datasets.\n",
        "\n",
        "6. **Visualization:**\n",
        "   - The heatmap visualization using seaborn indicates that there are no missing values (no color variation) in the dataset.\n",
        "\n",
        "7. **Potential Data Preprocessing:**\n",
        "   - Converting the 'Date' column to a datetime type would be useful for time-series analysis.\n",
        "   - Exploratory Data Analysis (EDA) and statistical analysis can be performed on numerical columns to understand patterns and trends.\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe().round(2)"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Date: The date of the stock closing price data.\n",
        "2. Open: The opening price of the stock on a given date.\n",
        "3. High: The highest price of the stock on a given date.\n",
        "4. Low: The lowest price of the stock on a given date.\n",
        "5. Close: The closing price of the stock on a given date."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "yesdata = df.copy()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yesdata[\"Date\"] = pd.to_datetime(yesdata['Date'].apply(lambda x: dt.strptime(x,\"%b-%y\")))"
      ],
      "metadata": {
        "id": "yaaE9MR9YMYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# yesdata[\"Year\"] = yesdata[\"Date\"].dt.year\n",
        "# yesdata[\"Month\"] = yesdata[\"Date\"].dt.month\n",
        "# yesdata.drop(\"Date\", axis=1, inplace = True)\n",
        "# print(yesdata.head())"
      ],
      "metadata": {
        "id": "bLgnJzr2G7QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yesdata.head()"
      ],
      "metadata": {
        "id": "wdesg9KIazRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yesdata.info()"
      ],
      "metadata": {
        "id": "FocMWqD7PuA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have converted the \"Date\" column to datetime format using pandas' to_datetime function. This allows for easier manipulation and analysis of the dates in the dataset. Additionally, I have not performed any further manipulations or analysis in this code snippet. However, with this dataset, one could perform various types of analysis such as calculating summary statistics, visualizing trends over time, identifying correlations between variables, and exploring seasonality patterns."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# Visualize the monthly closing prices over the years to identify any general trends.\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(yesdata['Date'], yesdata['Close'], marker='o', color= 'g',linestyle='-', linewidth=1)\n",
        "plt.title('Monthly Closing Prices of Yes Bank')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Closing Price')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WjzE83FezqJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific chart chosen is a line plot because it effectively visualizes the trend in the closing prices of Yes Bank's stock over time. The x-axis represents the date, and the y-axis represents the closing price. The line plot connects the closing prices for each date, making it easier to identify trends and patterns over time."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart reveals that the closing price of Yes Bank's stock has fluctuated significantly over time, with periods of both growth and decline. In the early years, there was a steady increase in the closing price, followed by a sharp decline around 2008-2009. There was another period of growth from around 2010 to 2018, but after 2018, the stock price experienced significant fluctuations."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights gained from the chart can potentially help inform investment decisions and trading strategies. Positive insights include identifying periods of growth and decline, which could help investors make informed decisions about buying, selling, or holding Yes Bank's stock. However, the significant fluctuations in the stock price after 2018 could also indicate a high level of volatility and risk, which may deter some investors. Therefore, while the insights may provide valuable information, the high volatility could pose a risk to investors, potentially leading to negative growth or losses in the investment."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Compare the highest and lowest monthly prices over the years to identify price volatility.\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(yesdata['Date'], yesdata['High'], label='Highest Prices', marker='o')\n",
        "plt.plot(yesdata['Date'], yesdata['Low'], label='Lowest Prices', marker='o')\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price')\n",
        "plt.title('Comparison of Highest and Lowest Monthly Prices Over the Years')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "\n",
        "# Show plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific chart chosen is a line plot with markers, comparing the highest and lowest monthly prices of Yes Bank stock over the years. This chart type was selected because it provides a clear visual comparison of two continuous variables over time."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that while the highest prices have fluctuated significantly over time, the lowest prices have generally been more stable. This suggests that the stock has experienced periods of high volatility but has maintained a relatively stable lower price range."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights gained from this chart can help inform investment strategies. For example, an investor might consider buying Yes Bank stock when it's near the lower end of its price range, anticipating that it might rise in the future. Conversely, if an investor is risk-averse, they might avoid investing when the stock is at its highest prices, to avoid potential losses during periods of volatility.\n",
        "\n",
        "One insight that could potentially lead to negative growth is if the chart shows a consistent downward trend in the highest prices over time. This could indicate that the stock has been underperforming, and investors may lose confidence in its future prospects, leading to further declines."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "# Analyze the monthly price differences to understand the magnitude of fluctuations.\n",
        "yesdata['Price_Diff'] = yesdata['Close'].diff()\n",
        "# Plot the monthly price differences\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(yesdata['Date'], yesdata['Price_Diff'], marker='o',color= 'y', linestyle='-')\n",
        "plt.title('Monthly Price Differences')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price Difference')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the line plot to visualize the monthly price differences because it offers a clear depiction of how the closing prices change over time. The 'Price_Diff' column measures the difference between the closing prices of consecutive months, and a line plot effectively showcases the trend in these differences."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows the monthly price differences, which helps identify periods of significant changes in the stock price. For instance, noticeable spikes or dips indicate months with substantial price fluctuations, potentially signaling significant events or market reactions."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights gained from this chart can be valuable for traders, investors, and analysts. Understanding the patterns of price differences can aid in making informed decisions regarding buying, selling, or holding Yes Bank stocks.\n",
        "\n",
        "While the insights from the chart can be valuable, they may also reveal periods of negative growth or market instability. Sharp declines in price differences might indicate a period of negative growth or market downturn, which could lead to potential losses for investors. However, this information is crucial for risk management and informed decision-making."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# Plot the monthly closing prices against the opening prices to observe potential patterns or discrepancies.\n",
        "\n",
        "# Calculate the price differences\n",
        "yesdata['Price_Diff'] = yesdata['High'] - yesdata['Low']\n",
        "\n",
        "# Plot the monthly closing prices against the price differences\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(yesdata['Date'], yesdata['Close'], marker='o', linestyle='-', color='blue', label='Closing Price')\n",
        "plt.bar(yesdata['Date'], yesdata['Price_Diff'], color='g', label='Price Difference', width=5)\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price')\n",
        "plt.title('Monthly Closing Prices vs Price Differences')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific chart chosen is a combination of a line plot and a bar plot, which is suitable for comparing two related variables (monthly closing prices and price differences) over time. The line plot shows the trend in monthly closing prices, while the bar plot visually represents the magnitude of price differences."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the chart, we can see that the monthly closing prices generally follow an upward trend, while the price differences fluctuate. This indicates that there are periods of high volatility in the stock prices."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights can help create a positive business impact by providing a better understanding of the stock's volatility and potential risk factors. By identifying periods of high volatility, investors can make more informed decisions and manage their portfolios more effectively.\n",
        "\n",
        "Negative growth in the stock prices can occur during periods of high volatility, as uncertainty and risk aversion may lead to decreased investor confidence and selling pressure. Additionally, large price differences may indicate market inefficiencies or manipulation, which can negatively impact the stock's performance."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "# Assess the correlation between monthly closing prices and the opening prices.\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(yesdata['Date'], yesdata['Open'], marker='o', label='Closing Prices', color='b')\n",
        "plt.plot(yesdata['Date'], yesdata['Close'], marker='o', label='Opening Prices', color='r')\n",
        "plt.title('Monthly Closing Prices vs Opening Prices')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific chart chosen is a line plot that compares the monthly closing prices and opening prices of Yes Bank's stock. This chart was chosen because it provides a clear visual representation of the relationship between these two variables over time."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insight from the chart is that the monthly closing prices and opening prices of Yes Bank's stock tend to follow a similar trend over time. When there are significant changes in the opening prices, there are usually corresponding changes in the closing prices."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights can potentially help create a positive business impact by providing investors and stakeholders with a better understanding of the relationship between opening and closing prices. This can inform investment decisions and strategies, potentially leading to better outcomes.\n",
        "\n",
        "There are no insights that lead to negative growth specifically from this chart. However, it's important to note that while there is a correlation between opening and closing prices, correlation does not imply causation. Other factors, such as market conditions, news, and economic factors, can also influence the stock's performance."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Investigate the correlation between monthly closing prices and the highest and lowest prices.\n",
        "\n",
        "# Set Date as index\n",
        "yesdata.set_index('Date')\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plotting High prices\n",
        "plt.plot(yesdata.index, yesdata['High'], label='High', color='blue')\n",
        "\n",
        "# Plotting Low prices\n",
        "plt.plot(yesdata.index, yesdata['Low'], label='Low', color='green')\n",
        "\n",
        "# Plotting Closing prices\n",
        "plt.plot(yesdata.index, yesdata['Close'], label='Close', color='red')\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price')\n",
        "plt.title('Monthly Closing, Highest, and Lowest Prices')\n",
        "plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific chart chosen is a line plot that shows the monthly highest (High), lowest (Low), and closing (Close) prices of Yes Bank's stock. This type of chart is commonly used to visualize the trend and fluctuations in stock prices over time, providing a comprehensive overview of the stock's performance."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the chart, we can observe the following insights:\n",
        "\n",
        "- The closing prices tend to follow a similar trend to the highest prices but often remain slightly lower.\n",
        "- The lowest prices generally follow a similar trend to the closing prices but can sometimes dip significantly lower."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights can be valuable for investors and traders in making informed decisions related to Yes Bank's stock. The understanding of the historical price trends can help investors assess the stock's volatility and potential risks. However, it's important to note that past performance is not indicative of future results, and investors should consider various factors before making investment decisions."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# Predict the relationship between opening and closing prices using scatter plot and regression line.\n",
        "sns.regplot(x='Open', y='Close', data=yesdata, scatter_kws={'color':'blue'}, line_kws={'color':'red'})\n",
        "plt.title('Scatter Plot with Regression Line')\n",
        "plt.xlabel('Open')\n",
        "plt.ylabel('Close')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific chart chosen is a scatter plot with a regression line because it is well-suited for visualizing the relationship between two continuous variables, 'Open' and 'Close'. The regression line helps to understand the linear relationship between these variables and enables us to estimate the 'Close' value for a given 'Open' value."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insight from the chart indicates a strong positive linear relationship between the 'Open' and 'Close' prices of the stock. As the 'Open' price increases, the 'Close' price also tends to increase, which suggests a positive correlation between the two variables."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insight of a positive correlation between 'Open' and 'Close' prices can help in making informed trading decisions, such as predicting the 'Close' price based on the 'Open' price and vice versa. This can potentially lead to positive business impacts by improving trading strategies and maximizing returns on investments.\n",
        "\n",
        "There are no insights from the chart that directly suggest negative growth. However, if there were a significant negative correlation between 'Open' and 'Close' prices, it could indicate a potential trading strategy for short selling or bearish trading. But in the given scenario of a positive correlation, there are no insights suggesting negative growth."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Predict monthly opening stock prices using seaborn's barplot for visualization and date-based subsetting.\n",
        "plt.figure(figsize=(18, 8))\n",
        "# Create a new DataFrame with every 12th date\n",
        "date_range = yesdata['Date'][::12]\n",
        "yesdata_sub = yesdata[yesdata['Date'].isin(date_range)]\n",
        "sns.barplot(x='Date', y='Open', data=yesdata_sub, palette='viridis')\n",
        "plt.title('Opening Price by Month', fontsize=18)\n",
        "plt.xlabel('Date', fontsize=14)\n",
        "plt.ylabel('Opening Price', fontsize=14)\n",
        "plt.xticks(rotation=45, fontsize=12, ha='right')\n",
        "plt.yticks(fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart chosen is a bar plot with the date on the x-axis and the opening price on the y-axis, with each bar representing a month. This type of chart is suitable for comparing opening prices across months as it provides a clear visual representation of the data."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that the opening prices fluctuate over the months, with some months having higher opening prices than others. For example, in 2013, the opening prices are generally higher from February to June and from October to December. This trend is also observed in 2014, 2015, and 2016. However, there are exceptions, such as in 2014, where the opening prices are higher in July and August compared to the other months."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights gained from the chart can help inform decision-making in the financial sector. For example, identifying months with consistently high opening prices may indicate periods of increased market activity or investor confidence, which could be leveraged for strategic investments or trading decisions. Conversely, months with lower opening prices may suggest periods of market uncertainty or reduced investor interest, which could be used to inform risk management strategies or asset allocation decisions."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "# Investigate correlations between variables in \"yesdata\" using a heatmap for visualization and analysis.\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(yesdata.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title('Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The heatmap is chosen because it provides a clear and concise way to visualize the correlation between different features in the dataset. The color gradient helps to quickly identify positive or negative correlations between variables."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The heatmap of the yesdata dataset shows the correlation between the Open, High, Low, and Close prices. We can see that these variables are highly correlated with each other, which is expected since they represent different aspects of the stock prices. The Close price shows the strongest correlation with the High price, which suggests that the closing price tends to follow the high price closely. This insight can be valuable for understanding the relationship between these variables and making informed decisions in financial analysis."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "# Visualize pairwise relationships between variables in a dataset using a pair plot for analysis.\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.pairplot(yesdata)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pair plot is a suitable choice for this analysis because it allows us to visualize relationships between multiple variables simultaneously. In this case, since the dataset has multiple numerical features such as Open, High, Low, and Close, a pair plot can help us understand how these variables are related to each other."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the pair plot, I can observe the following insights:\n",
        "\n",
        "- There is a positive correlation between Open and Close prices, as well as between High and Low prices.\n",
        "- The distribution of the features seems to be right-skewed, with a few outliers in some cases.\n",
        "- There is a strong linear relationship between High and Close prices, as well as between Low and Close prices.\n",
        "- There seems to be some seasonality in the data, with periodic fluctuations in the prices over time."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Statement 1:** There is a significant positive correlation between Open and Close prices.\n",
        "**Statement 2:** The distribution of Close prices is approximately normal.         \n",
        "**Statement 3:** There is a significant difference in Close prices before and after a certain year."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis (H0):** There is no correlation between Open and Close prices.     \n",
        "**Alternate Hypothesis (H1):** There is a significant correlation between Open and Close prices.\n",
        "\n"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Statement 1: Pearson correlation coefficient between Open and Close prices\n",
        "from scipy.stats import pearsonr\n",
        "corr, p_value = pearsonr(yesdata['Open'], yesdata['Close'])\n",
        "print(\"Pearson correlation coefficient:\", corr)\n",
        "print(\"P-value:\", p_value)"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " We will calculate the p-value of the Pearson correlation coefficient."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We chose Pearson correlation coefficient because it measures the linear correlation between two variables."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis (H0):** The distribution of Close prices is not normal.    \n",
        "**Alternate Hypothesis (H1):** The distribution of Close prices is normal."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import shapiro\n",
        "\n",
        "# Statement 2: Shapiro-Wilk Test for normality\n",
        "statistic, p_value = shapiro(yesdata['Close'])\n",
        "print(\"Test Statistic:\", statistic)\n",
        "print(\"P-value:\", p_value)"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will obtain the p-value from the Shapiro-Wilk Test."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shapiro-Wilk Test is commonly used to test for normality."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis (H0):** There is no significant difference in Close prices before and after a certain year.     \n",
        "**Alternate Hypothesis (H1):** There is a significant difference in Close prices before and after a certain year."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Splitting the data into two groups based on the year\n",
        "before_year_data = yesdata[yesdata['Date'] < '2018-11-01']\n",
        "after_year_data = yesdata[yesdata['Date'] >= '2018-11-01']\n",
        "\n",
        "# Statement 3: Independent t-test for Close prices before and after a certain year\n",
        "statistic, p_value = ttest_ind(before_year_data['Close'], after_year_data['Close'])\n",
        "print(\"Test Statistic:\", statistic)\n",
        "print(\"P-value:\", p_value)\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will calculate the p-value of the Independent t-test."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Independent t-test is suitable for comparing means of two groups."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# Missing Values/Null Values Count\n",
        "print(yesdata.isnull().sum())\n",
        "\n",
        "# Visualizing the missing values\n",
        "# Checking Null Value by plotting Heatmap\n",
        "sns.heatmap(yesdata.isnull(), cbar=False)"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code initially checks for missing values in the dataset using the isnull().sum() method, which returns the count of missing values in each column. It then visualizes the missing values using a heatmap from the seaborn library."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "z_scores = stats.zscore(yesdata[\"Close\"])\n",
        "outlier_indices = yesdata.index[abs(z_scores)>3]\n",
        "# print(\"Indices od outliers:\", outlier_indices)\n",
        "plt.scatter(df.index, df[\"Close\"], label=\"Close\")\n",
        "\n",
        "# Highlight the outliers with a red color\n",
        "plt.scatter(outlier_indices, yesdata.loc[outlier_indices, \"Close\"], color=\"red\", label=\"Outliers\")\n",
        "\n",
        "# Add labels and a legend\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Close\")\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code I used the Z-score method to detect outliers in the 'Close' column of the dataset. Z-score is calculated for each data point in the 'Close' column, and if the absolute value of the Z-score is greater than 3, the data point is considered an outlier. The outliers are then highlighted in the scatter plot using a red color.\n",
        "\n",
        "The Z-score method is used because it is a simple and widely used technique for detecting outliers. It standardizes the data and allows for easy comparison of data points across different scales. The threshold of 3 is commonly used, as it corresponds to a 99.7% confidence interval for normally distributed data."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# Feature Manipulation\n",
        "yesdata['Date'] = pd.to_datetime(yesdata['Date'])  # Convert 'Date' column to datetime\n",
        "yesdata['Year'] = yesdata['Date'].dt.year  # Extract year\n",
        "yesdata['Month'] = yesdata['Date'].dt.month  # Extract month\n",
        "yesdata['Day'] = yesdata['Date'].dt.day  # Extract day\n",
        "\n",
        "yesdata['Price_Diff'] = yesdata['High'] - yesdata['Low']  # Difference between High and Low prices\n",
        "yesdata['OC_Diff'] = yesdata['Open'] - yesdata['Close']  # Difference between Open and Close prices\n",
        "# Print the modified DataFrame\n",
        "print(yesdata.head())"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Selection\n",
        "# Let's say we select the following features for analysis\n",
        "selected_features = ['Year', 'Month', 'Open', 'High', 'Low', 'Close', 'Price_Diff', 'OC_Diff']\n",
        "\n",
        "# Create a new DataFrame with selected features\n",
        "selected_data = yesdata[selected_features]\n",
        "\n",
        "# Optionally, you can drop NaN values if any\n",
        "selected_data = selected_data.dropna()\n",
        "\n",
        "# Display the manipulated and selected data\n",
        "print(selected_data.head())"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manual feature selection is used here because it allows the analyst to choose features based on their understanding of the problem domain. It can be particularly useful when there are a large number of features and the analyst has specific insights into which features are likely to be important."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The selected features are all related to the stock market, which is the domain of the analysis. 'Year' and 'Month' capture the temporal aspect, 'Open', 'High', 'Low', and 'Close' are standard stock market indicators, and 'Price_Diff' and 'OC_Diff' are calculated differences between opening and closing prices, and opening and closing prices respectively. These features are all likely to be important because they capture different aspects of the stock market that could influence stock prices."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Create a MinMaxScaler object\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Define the columns to scale\n",
        "columns_to_scale = ['Open', 'High', 'Low', 'Close', 'Price_Diff', 'OC_Diff']\n",
        "\n",
        "# Apply Min-Max Scaling to the selected columns\n",
        "scaled_data = selected_data.copy() # Make a copy of the original DataFrame\n",
        "scaled_data[columns_to_scale] = scaler.fit_transform(scaled_data[columns_to_scale])\n",
        "# Drop any remaining NaN values\n",
        "scaled_data.dropna(inplace=True)\n",
        "# Display the scaled DataFrame\n",
        "print(scaled_data.to_string())\n"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used Min-Max Scaling to scale the data. This method rescales the data to a fixed range, typically 0 to 1, based on the minimum and maximum values of each feature. It is an appropriate method when the data is not normally distributed and when the algorithm used for modeling is sensitive to feature scaling. The Min-Max Scaling method preserves the shape of the original distribution, making it a good choice when the distribution of the data is important for the analysis."
      ],
      "metadata": {
        "id": "PJNQqL-2T8CP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X = scaled_data.drop(columns=[\"Close\"])\n",
        "y = scaled_data[\"Close\"]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shape of each set\n",
        "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Test set shape:\", X_test.shape, y_test.shape)\n",
        "\n",
        "# print split dataset\n",
        "# X_train\n",
        "# X_test\n",
        "# y_train\n",
        "# y_test\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the code snippet provided, a test size ratio of 0.2 (20%) has been used, meaning that 20% of the data is allocated to the test set, while the remaining 80% is allocated to the training set. This ratio is commonly used in machine learning practices as it strikes a balance between having enough data to train the model effectively (80%) and having enough data to evaluate the model's performance (20%). It helps prevent overfitting by ensuring that the model is evaluated on unseen data, thus providing a more accurate assessment of its generalization performance."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "lr = LinearRegression()\n",
        "# Fit the Algorithm\n",
        "lr.fit(X_train, y_train)\n",
        "# Predict on the model\n",
        "lr_pred = lr.predict(X_test)\n",
        "# Evaluate the performance of the model\n",
        "lr_mae = mean_absolute_error(y_test, lr_pred)\n",
        "lr_mse = mean_squared_error(y_test, lr_pred)\n",
        "lr_r2 = r2_score(y_test, lr_pred)\n",
        "# Print the evaluation metrics\n",
        "print(\"Mean Absolute Error:\", lr_mae)\n",
        "print(f\"Linear Regression MSE: {lr_mse}\")\n",
        "print(f\"Linear Regression R2 Score: {lr_r2}\")"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ML Model used is Linear Regression. Linear regression is a linear approach to modeling the relationship between a scalar dependent variable (in this case, the \"Close\" price of Yes Bank stock) and one or more independent variables (the features such as \"Year\", \"Month\", \"Open\", \"High\", \"Low\", \"Price_Diff\", and \"OC_Diff\")."
      ],
      "metadata": {
        "id": "8fDPhbiZ8fUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Residual plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.residplot(x=y_test, y=lr_pred, lowess=True, line_kws={'color': 'red'})\n",
        "plt.title('Residual Plot (Linear Regression)')\n",
        "plt.xlabel('Actual Close Price')\n",
        "plt.ylabel('Residuals')\n",
        "plt.show()\n",
        "\n",
        "# Scatter plot of actual vs. predicted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=y_test, y=lr_pred)\n",
        "plt.title('Actual vs. Predicted (Linear Regression)')\n",
        "plt.xlabel('Actual Close Price')\n",
        "plt.ylabel('Predicted Close Price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "# Define the hyperparameters grid\n",
        "param_grid = {\n",
        "    'fit_intercept': [True, False],\n",
        "    'positive': [True, False],\n",
        "    'copy_X': [True, False]\n",
        "}\n",
        "\n",
        "# Instantiate the GridSearchCV object\n",
        "lr_grid = GridSearchCV(LinearRegression(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit the grid search to the data\n",
        "lr_grid.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model and its parameters\n",
        "best_lr = lr_grid.best_estimator_\n",
        "best_params = lr_grid.best_params_\n",
        "\n",
        "# Predict using the best model\n",
        "lr_grid_pred = best_lr.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the best model\n",
        "lr_grid_mae = mean_absolute_error(y_test, lr_grid_pred)\n",
        "lr_grid_mse = mean_squared_error(y_test, lr_grid_pred)\n",
        "lr_grid_r2 = r2_score(y_test, lr_grid_pred)\n",
        "# Print the mean squared error for the best model\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Mean Absolute Error (GridSearchCV):\", lr_grid_mae)\n",
        "print(f\"Linear Regression MSE (GridSearchCV): {lr_grid_mse}\")\n",
        "print(f\"Linear Regression R2 Score (GridSearchCV): {lr_grid_r2}\")"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " I've used GridSearchCV to search through a grid of hyperparameters. I chose this technique because it exhaustively searches through all the combinations of hyperparameters, which is suitable for a small dataset like this one. It provides a systematic way to find the best hyperparameters for a model."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In both implementations, the evaluation metrics (Mean Absolute Error, Mean Squared Error, and R2 Score) are identical, indicating that there is no improvement in the model performance after hyperparameter optimization using GridSearchCV.\n",
        "\n",
        "Evaluation Metric Score Chart:\n",
        "- Mean Absolute Error: 3.563215788492901e-17\n",
        "- Mean Squared Error: 3.596804301544811e-33\n",
        "- R2 Score: 1.0\n",
        "\n",
        "Since the metrics remain the same before and after hyperparameter optimization, there is no change in the model's performance, and hence, there is no improvement observed."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "# Fit the Algorithm\n",
        "dt.fit(X_train, y_train)\n",
        "# Predict on the model\n",
        "dt_pred = dt.predict(X_test)\n",
        "# Evaluate the performance of the model\n",
        "dt_mse = mean_squared_error(y_test, dt_pred)\n",
        "dt_mae = mean_absolute_error(y_test, dt_pred)\n",
        "dt_r2 = r2_score(y_test, lr_pred)\n",
        "# Print the mean squared error for model\n",
        "print(f\"Decision Tree Regressor MSE: {dt_mse}\")\n",
        "print(\"Decision Tree Regressor MAE:\", dt_mae)\n",
        "print(f\"Decision Tree Regressor R2 Score: {dt_r2}\")"
      ],
      "metadata": {
        "id": "n-IOs7zl1BGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ML Model implemented in the code is Decision Tree Regressor. This model is used for regression tasks, where the target variable is continuous. The Decision Tree Regressor works by splitting the data into subsets based on the features. It makes decisions at each node based on a set of rules, which are learned from the data. The final prediction is made by aggregating the predictions of the leaf nodes."
      ],
      "metadata": {
        "id": "VBkC0gS56jSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Plotting the actual and predicted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, dt_pred, color='blue', label='Actual vs Predicted')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2, color='red', label='Perfect Prediction')\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('Decision Tree Regressor Actual vs Predicted')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cJUnJrDzLosj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "# Define the parameters for grid search\n",
        "param_grid = {'max_depth': [None, 2, 4, 6, 8, 10], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4, 8]}\n",
        "\n",
        "# Create an instance of the Decision Tree Regressor model\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Create an instance of GridSearchCV\n",
        "grid_search = GridSearchCV(dt, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "\n",
        "# Fit the GridSearchCV instance to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and the best score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "# Print the best parameters and the best score\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Score:\", best_score)\n",
        "\n",
        "# Use the best model to predict on the test data\n",
        "best_dt = grid_search.best_estimator_\n",
        "best_dt_pred = best_dt.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the best model\n",
        "best_dt_mse = mean_squared_error(y_test, best_dt_pred)\n",
        "\n",
        "# Print the mean squared error for the best model\n",
        "print(\"Best Decision Tree Regressor MSE:\", best_dt_mse)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used GridSearchCV for hyperparameter tuning because it exhaustively searches over a specified parameter grid and performs cross-validation, which helps in finding the best combination of hyperparameters for the model."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After hyperparameter tuning, the Decision Tree Regressor model's mean squared error (MSE) improved from the initial value. The improvement can be noted by comparing the MSE before and after tuning."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly! Here's a concise explanation of each evaluation metric's business indication and impact for the provided ML models:\n",
        "\n",
        "1. **Decision Tree Regressor MSE:**\n",
        "   - Business Indication: Measures the average squared difference between predicted and actual values.\n",
        "   - Business Impact: Lower MSE suggests better model accuracy, which translates to more reliable business decisions based on price predictions.\n",
        "\n",
        "2. **Best Decision Tree Regressor MSE (with Hyperparameter Optimization):**\n",
        "   - Business Indication: Measures the average squared difference between predicted and actual values for the best-tuned model.\n",
        "   - Business Impact: Lower MSE indicates improved accuracy due to hyperparameter tuning, enhancing the reliability of business decisions based on price predictions."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "# Fit the Algorithm\n",
        "rf.fit(X_train, y_train)\n",
        "# Predict on the model\n",
        "rf_pred = rf.predict(X_test)\n",
        "# Evaluate the performance of the model\n",
        "rf_mse = mean_squared_error(y_test, rf_pred)\n",
        "rf_mae = mean_absolute_error(y_test, rf_pred)\n",
        "rf_r2 = r2_score(y_test, lr_pred)\n",
        "# Print the mean squared error for model\n",
        "print(f\"Random Forest Regressor MSE: {rf_mse}\")\n",
        "print(f\"Random Forest Regressor MSE: {rf_mae}\")\n",
        "print(f\"Random Forest Regressor R2 Score: {rf_r2}\")"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "54liMLFRURAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Scatter plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, rf_pred, color='blue', alpha=0.5)\n",
        "plt.title('Random Forest Regressor: Actual vs Predicted')\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plotting the actual vs predicted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, rf_pred, color='blue', label='Predicted')\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label='Actual')\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs Predicted Values (Random Forest Regressor)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "# Define the hyperparameters to tune\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 5, 10, 15],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Instantiate the Random Forest Regressor\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Instantiate GridSearchCV with the Random Forest Regressor and the hyperparameters\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "\n",
        "# Fit the GridSearchCV to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Best hyperparameters: {best_params}\")\n",
        "\n",
        "# Instantiate the Random Forest Regressor with the best hyperparameters\n",
        "best_rf = RandomForestRegressor(**best_params, random_state=42)\n",
        "\n",
        "# Fit the best model to the training data\n",
        "best_rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "best_rf_pred = best_rf.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the best model\n",
        "best_rf_mse = mean_squared_error(y_test, best_rf_pred)\n",
        "print(f\"Best Random Forest Regressor MSE: {best_rf_mse}\")\n"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used Grid Search Cross Validation (GridSearchCV) to search for the best combination of hyperparameters. This technique is commonly used because it exhaustively searches through a specified subset of the hyperparameter space and evaluates the model performance using cross-validation, which helps in avoiding overfitting."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After performing hyperparameter tuning, we saw an improvement in the mean squared error (MSE) score. The MSE score decreased from the previous value, indicating that the model with the best hyperparameters performs better than the initial model."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the evaluation of the three machine learning models, I considered the Mean Squared Error (MSE) as the primary metric for assessing their performance. MSE measures the average of the squares of the errors or deviations, which provides a good measure of how well the model predictions align with the actual values. It's a widely used metric in regression tasks as it penalizes large errors more, giving a more balanced view of the model's performance across the dataset.\n"
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the three models created, the Decision Tree Regressor is chosen as the final prediction model. This decision is based on the evaluation metrics, specifically the Mean Squared Error (MSE) and Mean Absolute Error (MAE), which are lower for the Decision Tree Regressor compared to the other models. Additionally, the R2 Score, which measures the proportion of the variance in the dependent variable that is predictable from the independent variables, is the same for all models, indicating that the Decision Tree Regressor provides the best predictive performance with the least error."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used three different models for the prediction task: Linear Regression, Decision Tree Regressor, and Random Forest Regressor. Each model has its own strengths and weaknesses, and the choice of the model depends on the nature of the data and the problem at hand.\n",
        "\n",
        "1. Linear Regression: This model is based on the assumption that the relationship between the input features and the output variable is linear. It is simple, interpretable, and computationally efficient. However, it may not capture complex relationships in the data.\n",
        "\n",
        "2. Decision Tree Regressor: This model is based on a tree-like structure where each node represents a decision based on the input features. It can capture complex relationships in the data and is interpretable. However, it is prone to overfitting and may not generalize well to new data.\n",
        "\n",
        "3. Random Forest Regressor: This model is an ensemble of decision trees where each tree is trained on a random subset of the data. It can capture complex relationships in the data and is less prone to overfitting compared to a single decision tree. However, it is less interpretable compared to a single decision tree.\n",
        "\n",
        "To interpret the feature importance of the models, I can use a model explainability tool like SHAP (SHapley Additive exPlanations). SHAP values provide a unified measure of feature importance for different models and can be used to explain the output of any machine learning model. By analyzing the SHAP values, I can identify which features are most important for the predictions and gain insights into the underlying relationships in the data."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In conclusion, all three machine learning models, Linear Regression, Decision Tree Regressor, and Random Forest Regressor, achieved excellent performance on the test dataset with R2 scores of 1.0. This indicates that the models perfectly predict the target variable. However, when considering other metrics, such as Mean Squared Error (MSE) and Mean Absolute Error (MAE), the Decision Tree Regressor and Random Forest Regressor outperformed the Linear Regression model. The Decision Tree Regressor had the lowest MSE and MAE, suggesting it was the most accurate in predicting the Yes Bank Stock Closing Prices, followed closely by the Random Forest Regressor."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}